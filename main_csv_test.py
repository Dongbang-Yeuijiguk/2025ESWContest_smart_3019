# main_csv_test.py

import time
import config
import pandas as pd
from tqdm import tqdm
from data_source.csv_reader import CSVReader
from pipeline.inference_pipeline import InferencePipeline
from logic.sleep_state_manager import SleepStateManager

import sys
import os


class MockInfluxWriter:
    """
    A mock InfluxDB writer for testing. It mimics the real writer's methods
    but doesn't actually connect to a database.
    """
    def write_state_change(self, user_id: str, new_state: str):
        pass
    def write_result(self, **kwargs):
        pass


class Tee:
    def __init__(self, *files):
        self.files = files
    def write(self, obj):
        for f in self.files:
            f.write(obj)
            f.flush()  # ì¦‰ì‹œ íŒŒì¼ì— ì“°ë„ë¡ flush
    def flush(self):
        for f in self.files:
            f.flush()


def main_test(csv_file_path: str):
    """
    Main function for testing the pipeline with a CSV file.
    Initializes all components, including the sleep manager, and processes the file.
    """
    
    original_stdout = sys.stdout  # ë‚˜ì¤‘ì— ë³µì›í•˜ê¸° ìœ„í•´ ì›ë˜ì˜ í‘œì¤€ ì¶œë ¥ì„ ì €ì¥
    
    # CSV íŒŒì¼ ì´ë¦„(í™•ì¥ì ì œì™¸)ì„ ê¸°ë°˜ìœ¼ë¡œ ë¡œê·¸ íŒŒì¼ ì´ë¦„ì„ ìƒì„±í•©ë‹ˆë‹¤.
    # ì˜ˆ: SLEEP_1010.csv -> SLEEP_1010_log.txt
    base_name = os.path.splitext(os.path.basename(csv_file_path))[0]
    log_file_name = f"{base_name}_log.txt"

    try:
        # 'utf-8' ì¸ì½”ë”©ìœ¼ë¡œ ë¡œê·¸ íŒŒì¼ì„ ì—½ë‹ˆë‹¤.
        with open(log_file_name, 'w', encoding='utf-8') as log_file:
            # sys.stdoutì„ Tee í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ë¡œ ë°”ê¿‰ë‹ˆë‹¤.
            # ì´ì œë¶€í„° print()ë‚˜ tqdm.write()ëŠ” ëª¨ë‘ ì›ë˜ ì½˜ì†”ê³¼ log_file ì–‘ìª½ì— ì“°ê²Œ ë©ë‹ˆë‹¤.
            sys.stdout = Tee(original_stdout, log_file)
            
            # --- [ê¸°ì¡´ main_test ë¡œì§ ì‹œì‘] ---
            # (ì´ ì•ˆì˜ ì½”ë“œëŠ” ì „í˜€ ìˆ˜ì •í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤)
            
            print("=" * 50)
            print("ğŸš€ Starting CSI Inference Pipeline Test with CSV File.")
            print("=" * 50)

            try:
                # --- 1. Initialize pipeline and data source ---
                print("[1/4] Initializing Inference Pipeline...")
                pipeline = InferencePipeline(config)

                print("[2/4] Initializing Sleep State Manager (with Mock Writer)...")
                mock_writer = MockInfluxWriter()
                sleep_manager = SleepStateManager(
                    user_id=config.USER_ID,
                    writer=mock_writer
                )

                timestamp_col = 'real_timestamp'
                print(f"[3/4] Pre-calculating total chunks for progress bar...")
                timestamps = pd.read_csv(csv_file_path, usecols=[timestamp_col])[timestamp_col]
                total_duration_sec = timestamps.iloc[-1] - timestamps.iloc[0]
                
                print("-" * 20)
                print(f"ğŸ•’ First Timestamp: {timestamps.iloc[0]}")
                print(f"ğŸ•’ Last Timestamp:  {timestamps.iloc[-1]}")
                print(f"â±ï¸ Total Duration of CSV: {total_duration_sec:.2f} seconds")
                print(f"âœ‚ï¸ Window Size (from config): {config.WINDOW_SECONDS} seconds")
                print("-" * 20)

                total_chunks = int((total_duration_sec - config.WINDOW_SECONDS) / config.STEP_SECONDS) + 1
                if total_chunks < 0: total_chunks = 0
                print(f"Total chunks to process: {total_chunks}")

                print(f"[4/4] Initializing CSV Reader for file: {csv_file_path}...")
                csv_reader = CSVReader(
                    file_path=csv_file_path,
                    window_sec=config.WINDOW_SECONDS,
                    step_sec=config.STEP_SECONDS,
                    timestamp_col=timestamp_col
                )

                print("\nâœ… All components initialized successfully.")

            except Exception as e:
                print(f"âŒ Critical error during initialization: {e}")
                return

            print("\nâ–¶ï¸ Starting inference process from CSV file...\n")
            start_time = time.time()

            for csi_df_chunk in tqdm(csv_reader, total=total_chunks, desc="Processing Chunks"):
                if csi_df_chunk.empty:
                    continue
                
                result = pipeline.process(csi_df_chunk)

                if result:
                    # 1. First, calculate window_start from the data chunk.
                    window_start = csi_df_chunk['real_timestamp'].min()
                    
                    # 2. Then, pass it to the sleep manager.
                    current_sleep_state = sleep_manager.update_status(result, current_timestamp=window_start)
                    
                    # The rest of the code is the same.
                    tqdm.write(
                        f"[{window_start:.2f}s] Status: {result.get('status', 'N/A')}, "
                        f"Movement: {result.get('movement', 'N/A')} (Conf: {result.get('movement_conf', 0.0):.2f}), "
                        f"SleepState: {current_sleep_state}, "
                        f"BPM: {result.get('bpm', 0.0):.2f} (Conf: {result.get('bpm_conf', 0.0):.2f})"
                    )

            end_time = time.time()
            print("\n" + "=" * 50)
            print(f"âœ… CSV processing finished.")
            print(f"Processed {total_chunks} chunks in {end_time - start_time:.2f} seconds.")
            print("=" * 50)
            
            # --- [ê¸°ì¡´ main_test ë¡œì§ ë] ---

    finally:
        sys.stdout = original_stdout
        # ë¡œê·¸ íŒŒì¼ ì €ì¥ ìœ„ì¹˜ë¥¼ ì½˜ì†”ì— ë§ˆì§€ë§‰ìœ¼ë¡œ ì•Œë ¤ì¤ë‹ˆë‹¤.
        print(f"\nLog file saved to: {log_file_name}")


if __name__ == "__main__":
    CSV_FILE = "C:\\Users\\ssalt\\SOOM\\dataset\\full\\SLEEP_1010.csv"
    main_test(CSV_FILE)